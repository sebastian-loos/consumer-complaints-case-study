---
title: "consumer-complaint-modeling"
author: "Sebastian Camilo Loos"
date: "2023-09-13"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup_chunks, include=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "images/",
  out.width = "100%",
  message = FALSE,
  warning = FALSE,
  eval = FALSE
)
```

## Load Packages

```{r load_packages, eval=TRUE}
library(readr)
library(here)
library(tidyverse)
library(tidytext)
library(tidymodels)
library(SnowballC)
library(tm)
library(rsample)
library(recipes)
library(rpart)
library(tune)
library(vip)
library(workflows)
library(randomForest)
```

## Load data sets

```{r load_datasets}
training_data <- read_csv(here::here("data", "raw_data", "data_complaints_train.csv")) |>
  janitor::clean_names()

# organize variable names and types
training_data <- training_data |> 
  select(-submitted_via) |> 
  mutate(complaint_id = as.factor(row_number()), .before = everything(),
         product = as.factor(product)) |> 
  rename(complaint = consumer_complaint_narrative)
training_data

testing_data <- read_csv(here::here("data", "raw_data", "data_complaints_test.csv")) |>
  janitor::clean_names() |> 
  select(-submitted_via) |> 
  rename(complaint = consumer_complaint_narrative)
testing_data

# save(training_data, testing_data, file = here::here("data", "tidy_data", "project_5.rda"))
```

## Explore data

```{r explore_data}
head(training_data)
glimpse(training_data)
head(testing_data)
glimpse(testing_data)

skimr::skim(training_data)
skimr::skim(testing_data)
```

For the training data we have initially 90'975 complaints (rows) and 6 total variables (columns) where no values are missing. We have 4 different products for which the distribution can be seen in the following plot.

```{r plot_product_distribution}
training_data |> 
  group_by(product) |> 
  summarise(count = n()) |> 
  mutate(percent = count / sum(count) * 100 ) |>  
  ungroup() |>  
  arrange(desc(count)) |> 
  ggplot(aes(x = "", y = percent, fill = product)) +
  geom_col(color = "black") +
  geom_text(aes(label = round(percent, digits = 1)),
            position = position_stack(vjust = 0.5)) +
  coord_polar(theta = "y") +
  scale_fill_brewer() +
  labs(title = "Distribution of products for the training dataset.",
       x = "",
       y = "Percentage of Product Type") +
  guides(fill = guide_legend(title = "Product")) +
  theme(axis.text = element_blank(),
        axis.ticks = element_blank(),
        panel.grid = element_blank(),
        panel.background = element_rect(fill = "#ebf2ff"),
        plot.background = element_rect(fill = "#ebf2ff"),
        legend.background = element_rect(fill = "#ebf2ff"))

ggsave(here::here("images", "distribution-training.png"), width= 7, height = 4)

```

![](images/distribution-training.png)

There is no clear tendency visible between the length of a complaint and the product type. Only the complaints in the Mortgage category are slightly longer than the rest.

```{r plot_histogramm}
training_data |> 
  mutate(textlength = nchar(complaint), .after = complaint) |> 
  ggplot(mapping = aes(x = textlength)) +
  geom_histogram(binwidth = 200) +
  scale_x_continuous(limits = c(0, 4000)) + 
  facet_grid(product ~ .) + 
  labs(y = "Product", x = "Length of text in characters", title = "Histogram of the length of the complaints for each category") +
  theme_light()
  
ggsave(here::here("images", "histogram-training.png"), width= 7, height = 4)
  
training_data |> 
  mutate(textlength = nchar(complaint), .after = complaint) |> 
  ggplot(mapping = aes(x = textlength, product)) +
  geom_boxplot(outlier.shape = NA) +
  scale_x_continuous(limits = c(0, 3500)) + 
  labs(y = "Product", x = "Length of text in characters", title = "Boxplot of the length of the complaints for each category") +
  theme_light()

ggsave(here::here("images", "boxplot-training.png"), width= 7, height = 4)
```

![](images/boxplot-training.png)

## Term frequency

From the exploring of the data, no correlation between the different variables were visible. The most promising way to design the model is to create a matrix with how frequent a given word appears for a given complaint and use it as features for a machine learning algorithm. In the following the matrix is generated.

### Data preparation

#### Reducing Sample Size for Concept Proving

```{r reduce_size}
# set.seed(1234)
# # reduce sample size
# training_data <- training_data |>
#   sample_n(1000)
```

#### Create tidy data set

First, tidy the data to have a little bit and remove the X's and numbers.

```{r tidy_train_data}
complaints_train_tidy <- training_data |> 
  mutate(
    # lower case
    complaint = str_to_lower(complaint),
    
    # remove any strings such as "XX", "XXX", "XXXX" in the complaints
    complaint = str_replace_all(complaint, "xx+", "")) |> 
  
   # remove digits and punctuation
  mutate(
    complaint = removePunctuation(complaint),
    complaint = stripWhitespace(complaint),
    complaint = str_replace_all(complaint,'[0-9]+', ""),
    complaint = str_trim(complaint)
  )
```

### Variation 2

I tried out different ways to implement the model. Some included manipulating the complaints within the tibble, creating the DTM and narrowing the terms later. Different methods to create and manipulate the dtm were also explored. There was no specific reason for staying with this variation and later in the project I discovered more convenient methods that might have done this better/prettier.

```{r create_train_dtm}
complaints_train_corpus <- Corpus(VectorSource(complaints_train_tidy$complaint))
print(complaints_train_corpus)

inspect(complaints_train_corpus[1:5])

complaints_train_dtm <- DocumentTermMatrix(complaints_train_corpus,
                                             control = list(
                                       stripWhitespace = TRUE,
                                       stopwords = TRUE,
                                       stemming = TRUE,
                                       removeNumbers = TRUE,
                                       wordLengths = c(4, Inf),
                                       removePunctuation = TRUE
                                       ))
```

#### Inspection

As you can see the Matrix is very big.

```{r inspect_dtm}
inspect(complaints_train_dtm)
```

```         
<<DocumentTermMatrix (documents: 90975, terms: 52200)>>
Non-/sparse entries: 5778682/4743116318
Sparsity           : 100%
Maximal term length: 1961
Weighting          : term frequency (tf)
Sample             :
       Terms
Docs    account call card credit loan month payment receiv time told
  19650       4    8    0      4   51     1      13     21   10    0
  25455      97    0    0     15   81    12      33      5    4    0
  27671       3    1    0      1    4     0      13      3    4    0
  33614       5    2    7      6    8     2       1     20    5    0
  58908      24    1    0     27   62    63      54      3   19    0
  64243       0   14    0      0   84     7      11     11   23    2
  70389       1    1    2      4    6     3       3      2    0    0
  73540      16    5    0      9   64     4      44      6   11    0
  77518       0    0    0      0  854    16      46      0    0    2
  84551      58    0    0     12   70     6      38      0    8    0
```

#### Remove Sparse Terms

```{r spars_train_dtm}
# complaints_train_dtm <- removeSparseTerms(complaints_train_dtm, 0.90)
complaints_train_dtm <- removeSparseTerms(complaints_train_dtm, 0.95)
# complaints_train_dtm <- removeSparseTerms(complaints_train_dtm, 0.97)

inspect(complaints_train_dtm)
```

```         
<<DocumentTermMatrix (documents: 90975, terms: 312)>>
Non-/sparse entries: 3526661/24857539
Sparsity           : 88%
Maximal term length: 10
Weighting          : term frequency (tf)
Sample             :
       Terms
Docs    account call card credit loan month payment receiv time told
  11002       1    0    0      1   70     5       8     11   15    1
  19650       4    8    0      4   51     1      13     21   10    0
  25455      97    0    0     15   81    12      33      5    4    0
  37990      20   32    0     11   47    11      10     31   12    9
  56802      20   10    0      0    6     9      34     28   14    8
  60769       0   27    6      5   47    12      11     30   17   18
  68621      11   15    0     10   67     8      25     21   23    8
  73540      16    5    0      9   64     4      44      6   11    0
  77518       0    0    0      0  854    16      46      0    0    2
  84551      58    0    0     12   70     6      38      0    8    0
```

### Add meta data

```{r merge_train_dtm}
create_matrix <- function(dtm, meta){
  complaints_matrix <- as.matrix(dtm)
  complaints_matrix
  
  model_matrix <- meta |> 
    cbind(complaints_matrix) |>
    as_tibble()
  
  return(model_matrix)
}

complaints_train_meta <- training_data |> 
  select(-complaint) |> 
  rename(product_value = product,
         company_dummy = company,
         state_dummy = state)

complaints_train_merge <- create_matrix(complaints_train_dtm, complaints_train_meta)

```

```{r}
save.image(file='preprocessing.RData')
```

# Modeling

## Model 1: Classification And Regression Tree (CART) using rpart

```{r rpart_define_data}
cart_modeling_data <- complaints_train_merge
```

### Step 1: Data Splitting with rsample

```{r rpart_split}
# ensure the split is done the same if code is rerun
set.seed(1234)
# split data set into test and training
cart_modeling_data_split <- initial_split(cart_modeling_data, prop = 2/3) 
cart_modeling_data_split
```

```         
<Training/Testing/Total>
<60650/30325/90975>
```

```{r rpart_train_test}
cart_train <- training(cart_modeling_data_split)
count(cart_train, product_value)

cart_test <-testing(cart_modeling_data_split)
count(cart_test, product_value)
```

### Step 2: Create recipe with recipe()

```{r rpart_recipe}
cart_recipe <- cart_train |>
  recipe(product_value ~ .) |> 
  update_role(complaint_id, new_role = "comlaint id") |> 
  # Specify preprocessing steps 
  step_dummy(state_dummy, company_dummy, zip_code, one_hot = TRUE) |> 
  step_nzv(all_predictors()) #|> 
  # step_corr(all_predictors())
cart_recipe

summary(cart_recipe)
```

```         
── Recipe ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────

── Inputs 
Number of variables by role
outcome:       1
predictor:   315
comlaint id:   1

── Operations 
• Dummy variables from: state_dummy, company_dummy, zip_code
• Sparse, unbalanced variable filter on: all_predictors()
```

#### Check the preprocessing

```{r rpart_check_prep}
cart_preprocessing <- prep(cart_recipe, verbose = TRUE, retain = TRUE)

names(cart_preprocessing)
```

```         
oper 1 step dummy [training] 
oper 2 step nzv [training] 
The retained training set is ~ 122.19 Mb  in memory.

 [1] "var_info"       "term_info"      "steps"          "template"       "levels"   [6] "retained"       "requirements"   "tr_info"        "orig_lvls"
 [10]"last_term_info"
```

##### Take a look at preprocessed training data

```{r rpart_look}
cart_train_preproc <- bake(cart_preprocessing, new_data = NULL)
# glimpse(cart_train_preproc)
```

##### Extract preprocessed testing data using bake()

```{r rpart_extract_prep}
cart_test_baked <- bake(cart_preprocessing, new_data = cart_test)
# glimpse(cart_test_baked)
```

### Step 3: Specify model, engine, and mode using parsnip

```{r rpart_model}
cart_model <- 
  # define Model (Classification And Regression Tree (CART))
  parsnip::decision_tree() |>
  #set engine (rpart)
  parsnip::set_engine("rpart") |>
  # set mode (classification)
  parsnip::set_mode("classification")

cart_model
```

```         
Decision Tree Model Specification (classification)

Computational engine: rpart 
```

### Step 4: Create workflow, add recipe, add model

```{r rpart_workflow}
cart_wflow <- workflows::workflow() |>
                   workflows::add_recipe(cart_recipe) |>
                   workflows::add_model(cart_model)

cart_wflow
```

### Step 5.1 Fit model to training data

```{r rpart_fit}
doParallel::registerDoParallel(cores=11)

cart_fit <- parsnip::fit(cart_wflow, data = cart_train)
cart_fit
```

```         
 ══ Workflow [trained] ════════════════════════════════════════════════════════════
Preprocessor: Recipe
Model: decision_tree()

── Preprocessor ───────────────────────────────────────────────────────────────────
2 Recipe Steps

• step_dummy()
• step_nzv()

── Model ──────────────────────────────────────────────────────────────────────────
n= 60650 

node), split, n, loss, yval, (yprob)
      * denotes terminal node
```

#### Assessing the Model Fit

```{r rpart_assess_fit}
cart_fit_parsnip <- cart_fit |> 
  extract_fit_parsnip()
```

#### Explore Variable importance

```{r rpart_importance}
broomstick::tidy(cart_fit_parsnip) |> head(n = 20)

cart_fit |>
  extract_fit_parsnip() |>  
  vip(num_features = 20)

ggsave(here::here("images", "importance.png"), width= 7, height = 4)
```

![Importance values of the most important features for the model.](images/importance.png)

### Step 6: Get predictions

#### Pull out our predicted outcome values

```{r rpart_pull_fail}
# cart_fitted_values <- 
#   broomstick::augment(cart_fit_parsnip, new_data = cart_train)
# broom::augment()
# head(cart_fitted_values)
```

```{r rpart_merge_pred}
cart_fit_train_pred <- predict(cart_fit, new_data = cart_train)

cart_predicted_values <- cart_fit_train_pred |> 
  bind_cols(cart_train |> select(product_value, complaint_id, company_dummy, state_dummy, zip_code))
cart_predicted_values

```

```         
 # A tibble: 60,650 × 6
   .pred_class       product_value complaint_id company_dummy state_dummy
   <fct>             <fct>         <fct>        <chr>         <chr>      
 1 Student loan      Student loan  41964        HEARTLAND PA… NY         
 2 Student loan      Mortgage      15241        NATIONSTAR M… VA         
 3 Student loan      Student loan  33702        AES/PHEAA     NJ         
 4 Mortgage          Mortgage      83023        U.S. BANCORP  MI         
 5 Student loan      Student loan  80756        Performant F… CA         
 6 Student loan      Student loan  85374        AES/PHEAA     OH         
 7 Student loan      Mortgage      68158        RUSHMORE LOA… NY         
 8 Student loan      Student loan  59944        Navient Solu… MI         
 9 Credit card or p… Credit card … 68536        U.S. BANCORP  NC         
10 Mortgage          Vehicle loan… 17380        ALLY FINANCI… ME         
# ℹ 60,640 more rows
# ℹ 1 more variable: zip_code <chr>
# ℹ Use `print(n = ...)` to see more rows
```

#### Visualizing Model Performance

```{r rpart_plot_pred}
cart_predicted_values |>
  pivot_longer(c(.pred_class, product_value), names_to = "pred_or_orig", values_to = "products") |> 
  group_by(products, pred_or_orig) |> 
  summarise(count = n()) |> 
  group_by(pred_or_orig) |> 
  mutate(percent = count / sum(count) * 100) |>   
  ungroup() |>  
  arrange(desc(count)) |> 
  ggplot(aes(x = "", y = percent, fill = products)) +
  facet_grid(cols = vars(pred_or_orig),
             labeller = as_labeller(c(.pred_class = "Predictions",
                                      product_value = "Truth"))) +
  geom_col(color = "black") +
  geom_text(aes(label = round(percent, digits = 1)),
            position = position_stack(vjust = 0.5)) +
  coord_polar(theta = "y") +
  scale_fill_brewer() +
  labs(title = "Prediction and the true values for the distribution of products for the training dataset.",
       x = "",
       y = "Percentage of Product Type") +
  guides(fill = guide_legend(title = "Product")) +
  theme(axis.text = element_blank(),
        axis.ticks = element_blank(),
        panel.grid = element_blank(),
        panel.background = element_rect(fill = "#ebf2ff"),
        plot.background = element_rect(fill = "#ebf2ff"),
        legend.background = element_rect(fill = "#ebf2ff"))

ggsave(here::here("images", "pred-true-model-1.png"), width= 8, height = 4)
```

![](images/pred-true-model-1.png)

Looking at the graph, we can see that the performance of the model on the training data is not very satisfying. Especially the "Vehicle loan or lease" category is not recognized and instead the "Creadit card or prepaid card" category is predicted to often.

#### Quantifying Model Performance

To how the effectivness of the model we also calculate the accuracy of the prediction which is 0.799, but we want to achieve at least 0.8 (to hopefully pass the test;) if not more.

```{r rpart_perform}
yardstick::accuracy(cart_predicted_values, 
                truth = product_value, estimate = .pred_class)

count(cart_predicted_values, product_value)
count(cart_predicted_values, .pred_class)
```

```         
# A tibble: 1 × 3
  .metric  .estimator .estimate
  <chr>    <chr>          <dbl>
1 accuracy multiclass     0.799
```

### Assessing Model Performance on v-folds

So we want to see if a better performance is possible using v-folds cross validation.

#### Step 1.2 Split training set into cross validation sets

```{r rpart_vfold}
set.seed(1234)
cart_vfolds <- rsample::vfold_cv(data = cart_train, v = 5)
cart_vfolds

pull(cart_vfolds, splits)
```

```{r rpart_explore_vfold}
# Explore one of the folds
cart_first_fold <- cart_vfolds$splits[[1]]
head(as.data.frame(cart_first_fold, data = "analysis")) # training set of this fold

head(as.data.frame(cart_first_fold, data = "assessment")) # test set of this fold
```

### Step 5.2: Fit workflow with cross validation

```{r rpart_resample}
doParallel::registerDoParallel(cores=11)
set.seed(122)
cart_resample_fit <- tune::fit_resamples(cart_wflow, cart_vfolds)

cart_resample_fit

collect_metrics(cart_resample_fit)

show_best(cart_resample_fit, metrics = "accuracy")
```

```         
# A tibble: 2 × 6
  .metric  .estimator  mean     n std_err .config             
  <chr>    <chr>      <dbl> <int>   <dbl> <chr>               
1 accuracy multiclass 0.795     5 0.00313 Preprocessor1_Model1
2 roc_auc  hand_till  0.871     5 0.0121  Preprocessor1_Model1
```

We see that the best case doesn't achieve the 80 percent accuracy either. Also the area under the receiver operator curve can be improved and that's why we try an other model, the random forest model.

```{r}
save.image(file='cart.RData')
```

## Model 2: Random Forest

### Prepare Model data

We remove any additional variables to simplify the model. In this case it will now only be based on the text analysis of the complaints.

```{r rf_define_data}
rf_modeling_data <- complaints_train_merge |> 
  select(-c(company_dummy, state_dummy, zip_code))
```

### Perform initial simple model fit

#### Step 1: Data Splitting with rsample again

```{r rf_split}
# ensure the split is done the same if code is rerun
set.seed(1234)
# split data set into test and training
rf_modeling_data_split <- initial_split(rf_modeling_data, prop = 2/3) 
rf_modeling_data_split
```

```{r rf_train_test}
rf_train <- training(rf_modeling_data_split)
count(rf_train, product_value)

rf_test <-testing(rf_modeling_data_split)
count(rf_test, product_value)
```

#### Step 2: Create recipe with recipe()

```{r rf_recipe}
rf_recipe <- rf_train |>
  recipe(product_value ~ .) |> 
  update_role(complaint_id, new_role = "comlaint id") |> 
  # Specify preprocessing steps 
  # step_novel(company_dummy) |> 
  step_nzv(all_predictors()) #|> 
  # step_corr(all_predictors())
rf_recipe

summary(rf_recipe)
```

```         
── Recipe ─────────────────────────────────────────────────────────────────────────

── Inputs 
Number of variables by role
outcome:       1
predictor:   312
comlaint id:   1

── Operations 
• Sparse, unbalanced variable filter on: all_predictors()
```

#### Step 3: Specify model, engine, and mode using parsnip

```{r rf_model}
rf_simple_model <- 
  # define Model (Classification And Regression Tree (CART))
  parsnip::rand_forest(mtry = 10, min_n = 4) |>
  #set engine (rpart)
  parsnip::set_engine("randomForest") |>
  # set mode (classification)
  parsnip::set_mode("classification")

rf_simple_model
```

#### Step 4: Create workflow, add recipe, add model

```{r rf_workflow}
rf_simple_wflow <- workflows::workflow() |> 
            workflows::add_recipe(rf_recipe) |> 
            workflows::add_model(rf_simple_model)
rf_simple_wflow
```

#### Step 5.1 Fit workflow with cross validation

```{r rf_fit}
doParallel::registerDoParallel(cores=11)
rf_simple_wflow_fit <- parsnip::fit(rf_simple_wflow, data = rf_train)
rf_simple_wflow_fit
```

```         
══ Workflow [trained] ═════════════════════════════════════════════════════════════
Preprocessor: Recipe
Model: rand_forest()

── Preprocessor ───────────────────────────────────────────────────────────────────
1 Recipe Step

• step_nzv()

── Model ──────────────────────────────────────────────────────────────────────────

Call:
 randomForest(x = maybe_data_frame(x), y = y, mtry = min_cols(~10,      x), nodesize = min_rows(~4, x)) 
               Type of random forest: classification
                     Number of trees: 500
No. of variables tried at each split: 10

        OOB estimate of  error rate: 16.62%
Confusion matrix:
                            Credit card or prepaid card Mortgage Student loan
Credit card or prepaid card                       24861      473           65
Mortgage                                           1060    18652          804
Student loan                                        868     1586         5633
Vehicle loan or lease                              2154     1581         1104
                            Vehicle loan or lease class.error
Credit card or prepaid card                   100  0.02502059
Mortgage                                       98  0.09517803
Student loan                                  189  0.31935718
Vehicle loan or lease                        1422  0.77287973
```

#### Explore Variable importance using vip()

The importance has changed slightly, but the main drivers are still the same...

```{r rf_importance}
rf_simple_wflow_fit |> 
  extract_fit_parsnip() |> 
  vip(num_features = 20)

ggsave(here::here("images", "rf-importance.png"), width= 7, height = 4)
```

![](images/rf-importance.png)

### Assessing Model Performance on v-folds using tune

#### Step 1.2 Split training set into cross validation sets

```{r rf_vfold}
set.seed(1234)
rf_vfolds <- rsample::vfold_cv(data = rf_train, v = 5)
rf_vfolds

pull(rf_vfolds, splits)
```

```{r rf_resample}
doParallel::registerDoParallel(cores=8)

set.seed(456)
rf_simple_resample_fit <- tune::fit_resamples(rf_simple_wflow, rf_vfolds)
collect_metrics(rf_simple_resample_fit)

save.image(file='rf_vfold.RData')
```

```         
# A tibble: 2 × 6
  .metric  .estimator  mean     n  std_err .config             
  <chr>    <chr>      <dbl> <int>    <dbl> <chr>               
1 accuracy multiclass 0.835     5 0.00140  Preprocessor1_Model1
2 roc_auc  hand_till  0.932     5 0.000900 Preprocessor1_Model1
```

The metrics have improved with this model where we used the parameters `mtry` = 10 and `min_n` = 4. Let's see, if we can get an even better performance by tuning these parameters.

#### Step 3.2: Specify hyperparameters to tune (tune())

```{r rf_tune_model}
rf_tune_model <- 
  rand_forest(mtry = tune(), min_n = tune()) |>
  set_engine("randomForest") |>
  set_mode("classification")
rf_tune_model
```

#### Define worflow for tuning

```{r rf_tune_workflow}
rf_tune_wflow <- workflows::workflow() %>%
            workflows::add_recipe(rf_recipe) %>%
            workflows::add_model(rf_tune_model)
rf_tune_wflow
```

```         
══ Workflow ═══════════════════════════════════════════════════════════════════════
Preprocessor: Recipe
Model: rand_forest()

── Preprocessor ───────────────────────────────────────────────────────────────────
1 Recipe Step

• step_nzv()

── Model ──────────────────────────────────────────────────────────────────────────
Random Forest Model Specification (classification)

Main Arguments:
  mtry = tune()
  min_n = tune()

Computational engine: randomForest 
```

#### Step 5.3: Fit workflow with tuning

```{r rf_tune_fit}
doParallel::registerDoParallel(cores=10)
set.seed(123)
rf_tune_results <- tune::tune_grid(rf_tune_wflow, resamples = rf_vfolds)

rf_tune_results |> collect_metrics()
```

```         
# A tibble: 20 × 8
    mtry min_n .metric  .estimator  mean     n  std_err .config              
   <int> <int> <chr>    <chr>      <dbl> <int>    <dbl> <chr>                
 1    60    30 accuracy multiclass 0.850     5 0.00130  Preprocessor1_Model01
 2    60    30 roc_auc  hand_till  0.936     5 0.000869 Preprocessor1_Model01
 3   220     3 accuracy multiclass 0.846     5 0.00108  Preprocessor1_Model02
 4   220     3 roc_auc  hand_till  0.934     5 0.000867 Preprocessor1_Model02
 5    29    39 accuracy multiclass 0.847     5 0.00125  Preprocessor1_Model03
 6    29    39 roc_auc  hand_till  0.935     5 0.000819 Preprocessor1_Model03
 7    98    27 accuracy multiclass 0.849     5 0.000878 Preprocessor1_Model04
 8    98    27 roc_auc  hand_till  0.936     5 0.000806 Preprocessor1_Model04
 9   215    36 accuracy multiclass 0.844     5 0.00105  Preprocessor1_Model05
10   215    36 roc_auc  hand_till  0.933     5 0.000821 Preprocessor1_Model05
11    88    20 accuracy multiclass 0.851     5 0.000927 Preprocessor1_Model06
12    88    20 roc_auc  hand_till  0.936     5 0.000839 Preprocessor1_Model06
13   125    24 accuracy multiclass 0.848     5 0.000859 Preprocessor1_Model07
14   125    24 roc_auc  hand_till  0.935     5 0.000811 Preprocessor1_Model07
15   189    12 accuracy multiclass 0.848     5 0.000864 Preprocessor1_Model08
16   189    12 roc_auc  hand_till  0.934     5 0.000856 Preprocessor1_Model08
17   159    15 accuracy multiclass 0.848     5 0.000925 Preprocessor1_Model09
18   159    15 roc_auc  hand_till  0.935     5 0.000921 Preprocessor1_Model09
19    19     7 accuracy multiclass 0.848     5 0.00159  Preprocessor1_Model10
20    19     7 roc_auc  hand_till  0.935     5 0.000920 Preprocessor1_Model10
```

```{r rf_tune_best_accuracy}
tune::show_best(rf_tune_results, metric = "accuracy")
```

```         
# A tibble: 5 × 8
   mtry min_n .metric  .estimator  mean     n  std_err .config              
  <int> <int> <chr>    <chr>      <dbl> <int>    <dbl> <chr>                
1    88    20 accuracy multiclass 0.851     5 0.000927 Preprocessor1_Model06
2    60    30 accuracy multiclass 0.850     5 0.00130  Preprocessor1_Model01
3    98    27 accuracy multiclass 0.849     5 0.000878 Preprocessor1_Model04
4   159    15 accuracy multiclass 0.848     5 0.000925 Preprocessor1_Model09
5   125    24 accuracy multiclass 0.848     5 0.000859 Preprocessor1_Model07
```

```{r rf_tune_best_rocauc}
tune::show_best(rf_tune_results, metric = "roc_auc") 
```

```         
# A tibble: 5 × 8
   mtry min_n .metric .estimator  mean     n  std_err .config              
  <int> <int> <chr>   <chr>      <dbl> <int>    <dbl> <chr>                
1    60    30 roc_auc hand_till  0.936     5 0.000869 Preprocessor1_Model01
2    88    20 roc_auc hand_till  0.936     5 0.000839 Preprocessor1_Model06
3    98    27 roc_auc hand_till  0.936     5 0.000806 Preprocessor1_Model04
4    29    39 roc_auc hand_till  0.935     5 0.000819 Preprocessor1_Model03
5   125    24 roc_auc hand_till  0.935     5 0.000811 Preprocessor1_Model07
```

From the tuning valuation we see that the best results for accuracy are achieved with the following parameters:

-   `mtry = 88`

-   `min_n = 20`

Leading to a accuracy of 0.851 and an area under receiver operator curve of 0.936.

### Model performance evaluation

#### Select best tuning values for final fit

```{r final_values}
# Select best tuning values
rf_tunedd_values <- select_best(rf_tune_results, metric = "accuracy")
rf_tunedd_values
```

#### Create workflow for tuned Random Forest fit

```{r rf_tunedd_workflow}
# create final workflow
rf_tunedd_wflow <-rf_tune_wflow |> 
  tune::finalize_workflow(rf_tunedd_values)
rf_tunedd_wflow
```

```         
> rf_tunedd_wflow
══ Workflow ═══════════════════════════════════════════════════════════════════════
Preprocessor: Recipe
Model: rand_forest()

── Preprocessor ───────────────────────────────────────────────────────────────────
1 Recipe Step

• step_nzv()

── Model ──────────────────────────────────────────────────────────────────────────
Random Forest Model Specification (classification)

Main Arguments:
  mtry = 88
  min_n = 20

Computational engine: randomForest 
```

#### Perform tuned Random Forest fit

```{r rf_tunedd_overallfit}
doParallel::registerDoParallel(cores=11)

rf_tunedd_overallfit <- tune::last_fit(rf_tunedd_wflow, 
                                       split = rf_modeling_data_split)
rf_tunedd_overallfit
```

```{r rf_final_metrics}
collect_metrics(rf_tunedd_overallfit)
```

```         
# A tibble: 2 × 4
  .metric  .estimator .estimate .config             
  <chr>    <chr>          <dbl> <chr>               
1 accuracy multiclass     0.854 Preprocessor1_Model1
2 roc_auc  hand_till      0.936 Preprocessor1_Model1
```

The application on the test split data shows that the model performs similarly as to the training split data.

```{r rf_final_test_pred}
rf_pred_test_values <- collect_predictions(rf_tunedd_overallfit)
```

```{r}
rf_pred_test_values |> 
  select(-id) |> 
  relocate(.pred_class, product_value, .before = `.pred_Credit card or prepaid card`) |> 
  head(n = 15)
```

```         
# A tibble: 15 × 8
   .pred_class              product_value .pred_Credit card or…¹ .pred_Mortgage
   <fct>                    <fct>                          <dbl>          <dbl>
 1 Credit card or prepaid … Credit card …                  0.426          0.182
 2 Mortgage                 Credit card …                  0.36           0.52 
 3 Credit card or prepaid … Credit card …                  0.872          0.044
 4 Vehicle loan or lease    Mortgage                       0.012          0.404
 5 Credit card or prepaid … Credit card …                  0.998          0    
 6 Mortgage                 Mortgage                       0              0.998
 7 Credit card or prepaid … Credit card …                  0.996          0.002
 8 Vehicle loan or lease    Vehicle loan…                  0.346          0.088
 9 Mortgage                 Mortgage                       0.004          0.994
10 Credit card or prepaid … Mortgage                       1              0    
11 Student loan             Mortgage                       0              0.086
12 Mortgage                 Mortgage                       0              1    
13 Student loan             Mortgage                       0.01           0.364
14 Credit card or prepaid … Credit card …                  0.988          0.002
15 Mortgage                 Mortgage                       0              1    
# ℹ abbreviated name: ¹​`.pred_Credit card or prepaid card`
# ℹ 4 more variables: `.pred_Student loan` <dbl>,
#   `.pred_Vehicle loan or lease` <dbl>, .row <int>, .config <chr>
```

### Plot

```{r plot_true_pred}
rf_pred_test_values |>
  pivot_longer(c(.pred_class, product_value), names_to = "pred_or_orig", values_to = "products") |> 
  group_by(products, pred_or_orig) |> 
  summarise(count = n()) |> 
  group_by(pred_or_orig) |> 
  mutate(percent = count / sum(count) * 100) |>   
  ungroup() |>  
  arrange(desc(count)) |> 
  ggplot(aes(x = "", y = percent, fill = products)) +
  facet_grid(cols = vars(pred_or_orig),
             labeller = as_labeller(c(.pred_class = "Predictions",
                                      product_value = "Truth"))) +
  geom_col(color = "black") +
  geom_text(aes(label = round(percent, digits = 1)),
            position = position_stack(vjust = 0.5)) +
  coord_polar(theta = "y") +
  scale_fill_brewer() +
  labs(title = "Prediction and the true values for the distribution of products for the testing split \nof the training dataset.",
       x = "",
       y = "Percentage of Product Type") +
  guides(fill = guide_legend(title = "Product")) +
  theme(axis.text = element_blank(),
        axis.ticks = element_blank(),
        panel.grid = element_blank(),
        panel.background = element_rect(fill = "#ebf2ff"),
        plot.background = element_rect(fill = "#ebf2ff"),
        legend.background = element_rect(fill = "#ebf2ff"))

ggsave(here::here("images", "pred-true-model-final.png"), width= 8, height = 4)
```

![](images/pred-true-model-final.png){#fig-final-comparison}

As one can see, the good (but not perfect!) fit of the final model is also visible in the distribution of the different complaint/product categories for the test split of the whole training dataset.\
Further steps of analysis could include the analysis of sensitivity and specificity with regards to the the different categories, but because of the limited time this analysis will be skipped.

```{r save_rf_final}
save.image(file='rf_vfold.RData')
```

## Application of Final Model on Test Dataset

So finaly, we have to apply the model to our test dataset. Therefore, we have to perform the same preprocessing steps as done with the traininig dataset.

### Create tidy test data set

```{r tidy_test_data}
complaints_test_tidy <- testing_data |> 
  mutate(
    # lower case
    complaint = str_to_lower(complaint),
    
    # remove any strings such as "XX", "XXX", "XXXX" in the complaints
    complaint = str_replace_all(complaint, "xx+", "")) |> 
  
   # remove digits and punctuation
  mutate(
    complaint = removePunctuation(complaint),
    complaint = stripWhitespace(complaint),
    complaint = str_replace_all(complaint,'[0-9]+', ""),
    complaint = str_trim(complaint)
  )
```

```{r create_test_dtm}
# Create DTM for the test dataset
complaints_test_corpus <- Corpus(VectorSource(complaints_test_tidy$complaint))
print(complaints_test_corpus)

inspect(complaints_test_corpus[1:5])

complaints_test_dtm <- DocumentTermMatrix(complaints_test_corpus,
                                             control = list(
                                       stripWhitespace = TRUE,
                                       stopwords = TRUE,
                                       stemming = TRUE,
                                       removeNumbers = TRUE,
                                       wordLengths = c(4, Inf),
                                       removePunctuation = TRUE
                                       ))
```

```{r sparse_test_dtm}
# remove spars terms
complaints_test_dtm <- removeSparseTerms(complaints_test_dtm, 0.95)
```

```{r merge_test_dtm}
complaints_test_meta <- testing_data |> 
  select(problem_id)

complaints_test_merge <- create_matrix(complaints_test_dtm, complaints_test_meta)
complaints_test_merge

complaints_colnames <- rf_modeling_data |>
  head(n = 1) |> 
  select(-c(complaint_id, product_value)) |> 
  mutate(across(everything(), ~ 0))

final_test_data <- complaints_test_merge |> 
  full_join(complaints_colnames) |> 
  rename(complaint_id = problem_id) |> 
  mutate(complaint_id = as.factor(complaint_id)) |> 
  filter(complaint_id != 0) |> 
  mutate(across(!complaint_id, ~ replace(., is.na(.), 0)))
```

### Define final workflow (including recipe and model)

```{r final_wflow}
final_wflow <- rf_tunedd_wflow
final_wflow
```

```         
══ Workflow ═════════════════════════════════════════════════════════════════════════════════
Preprocessor: Recipe
Model: rand_forest()

── Preprocessor ─────────────────────────────────────────────────────────────────────────────
1 Recipe Step

• step_nzv()

── Model ────────────────────────────────────────────────────────────────────────────────────
Random Forest Model Specification (classification)

Main Arguments:
  mtry = 88
  min_n = 20

Computational engine: randomForest 
```

### Perform final fit

```{r final_fit}
doParallel::registerDoParallel(cores=11)

final_fit <- parsnip::fit(final_wflow, data = rf_train)
final_fit
```

```         
══ Workflow [trained] ═════════════════════════════════════════════════════════
Preprocessor: Recipe
Model: rand_forest()

── Preprocessor ───────────────────────────────────────────────────────────────
1 Recipe Step

• step_nzv()

── Model ──────────────────────────────────────────────────────────────────────

Call:
 randomForest(x = maybe_data_frame(x), y = y, mtry = min_cols(~88L,      x), nodesize = min_rows(~20L, x)) 
               Type of random forest: classification
                     Number of trees: 500
No. of variables tried at each split: 88

        OOB estimate of  error rate: 14.94%
Confusion matrix:
                            Credit card or prepaid card Mortgage Student loan
Credit card or prepaid card                       24331      516          117
Mortgage                                            852    17938         1189
Student loan                                        615      839         6162
Vehicle loan or lease                              1307      689         1105
                            Vehicle loan or lease class.error
Credit card or prepaid card                   535  0.04580572
Mortgage                                      635  0.12981469
Student loan                                  660  0.25543741
Vehicle loan or lease                        3160  0.49528829
```

Before applying the final model on the testing data, let's have a look on the output that the final fit generated. It shows the values for the parameters that we received from tuning, but also the actual number of trees that the were used (500). The estimated error rate for out sample data of 14.94% correlates with the calculated accuracy values that we got with the best tuning parameters as seen in Section [Perform tuned Random Forest fit] which shows an accuracy of 85.4%. The output above also shows that the error will most likely be linked to the class "Vehicle loan or lease" or "Student loan".

### Predict Categories for test dataset

```{r predict_test_dataset}
final_test_predictions <- predict(final_fit, new_data = final_test_data)
```

```{r show_results}
testing_data |> 
  select(problem_id) |> 
  left_join(rowid_to_column(final_test_predictions, "problem_id")) |> 
  gt::gt() |>
  gt::tab_header(
    title = "Predictions of the Problem Classes with the Final Model") |> 
  gt::cols_label(.list = c("problem_id" = "Problem ID",
                           ".pred_class" = "Model Problem Prediction"))
```

![](images/predictions.png)

```{r save_final}
save.image(file='rf_final.RData')
```

```{r clean_up}
rm(
  complaints_train_corpus,
  complaints_train_dtm,
  complaints_train_meta,
  complaints_train_tidy,
  complaints_test_corpus,
  complaints_test_dtm,
  complaints_test_meta,
  complaints_test_tidy,
  rf_modeling_data_split,
  rf_simple_model,
  rf_simple_resample_fit,
  rf_simple_wflow,
  rf_simple_wflow_fit,
  rf_tune_wflow,
  rf_tune_results,
  rf_tunedd_overallfit,
  rf_tunedd_wflow
)

save.image(file='rf_final_small.RData')
```
